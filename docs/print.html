<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>neonrvm</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="neonrvm users guide.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "ayu" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="introduction.html">Introduction</a></li><li class="spacer"></li><li class="chapter-item expanded "><a href="building.html"><strong aria-hidden="true">1.</strong> Building neonrvm</a></li><li class="chapter-item expanded "><a href="using.html"><strong aria-hidden="true">2.</strong> Using neonrvm</a></li><li class="chapter-item expanded "><a href="data.html"><strong aria-hidden="true">3.</strong> Data preparation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="design_matrix.html"><strong aria-hidden="true">3.1.</strong> Design matrix preparation</a></li><li class="chapter-item expanded "><a href="training_cache.html"><strong aria-hidden="true">3.2.</strong> Creating training cache</a></li><li class="chapter-item expanded "><a href="training_parameters.html"><strong aria-hidden="true">3.3.</strong> Creating training parameters</a></li><li class="chapter-item expanded "><a href="training_model.html"><strong aria-hidden="true">3.4.</strong> Training the model</a></li><li class="chapter-item expanded "><a href="training_results.html"><strong aria-hidden="true">3.5.</strong> Getting the training results</a></li><li class="chapter-item expanded "><a href="predict.html"><strong aria-hidden="true">3.6.</strong> Making predictions</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="license.html">License</a></li><li class="chapter-item expanded affix "><a href="future.html">Future work</a></li><li class="chapter-item expanded affix "><a href="reference.html">Reference</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">neonrvm</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        <a href="https://github.com/siavashserver/neonrvm" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p align="center">
<img src="neonrvm.svg" alt="neonrvm_logo" title="neonrvm">
</p>
<p><img src="https://img.shields.io/github/license/siavashserver/neonrvm?style=flat-square" alt="GitHub" />
<img src="https://img.shields.io/github/v/release/siavashserver/neonrvm?include_prereleases&amp;style=flat-square" alt="GitHub release (latest SemVer including pre-releases)" />
<img src="https://img.shields.io/github/stars/siavashserver/neonrvm?style=flat-square" alt="GitHub stars" />
<img src="https://img.shields.io/pypi/status/neonrvm?style=flat-square" alt="PyPI - Status" /></p>
<h1><a class="header" href="#introduction" id="introduction">Introduction</a></h1>
<p><strong>neonrvm</strong> is an open source machine learning library for performing regression
tasks using <a href="https://en.wikipedia.org/wiki/Relevance_vector_machine">RVM</a> technique. It is written in C programming language and comes
with bindings for the Python programming language.</p>
<p>neonrvm was born during my master's thesis to help reduce training times and
required system resources. neonrvm did that by getting rid of multiple
middleware layers and optimizing memory usage.</p>
<p>Under the hood neonrvm uses expectation maximization fitting method, and allows
basis functions to be fed incrementally to the model. This helps to keep
training times and memory requirements significantly lower for large data sets.</p>
<p>neonrvm is not trying to be a full featured machine learning framework, and only
provides core training and prediction facilities. You might want to use it in
conjunction with higher level scientific programming languages and machine
learning tool kits instead.</p>
<p>RVM technique is very sensitive to input data representation and kernel
selection. You might consider something else if you are looking for a less
challenging solution.</p>
<h1><a class="header" href="#building-neonrvm" id="building-neonrvm">Building neonrvm</a></h1>
<p>You can build neonrvm as a dynamic or static library; or manually include
<code>neonrvm.h</code> and <code>neonrvm.c</code> in your C/C++ project and handle linkage of the
required dependencies.</p>
<p>A C99 compiler is required in order to compile neonrvm, you can find one in
every house these days. You also need <a href="https://cmake.org/">CMake</a> to configure and generate build
files.</p>
<p>neonrvm requires a linear algebra library providing BLAS/LAPACK interface to do
its magic. Popular ones are <a href="https://software.intel.com/mkl">Intel MKL</a>, <a href="http://www.openblas.net/">OpenBLAS</a>, and the reference <a href="http://www.netlib.org/lapack/">Netlib
LAPACK</a>. OpenBLAS is almost as fast as Intel MKL, and unlike competition it
doesn't require you to go through a lengthy registration process.</p>
<h2><a class="header" href="#c-library" id="c-library">C library</a></h2>
<p>Please run the following commands inside the source directory to build the
library and examples:</p>
<pre><code class="language-Shell">$ git clone https://github.com/siavashserver/neonrvm.git
$ cd neonrvm
$ mkdir build
$ cd build
$ cmake ..
$ cmake --build . --config Release
</code></pre>
<p>It is recommended to use <a href="https://cmake.org/cmake/help/latest/module/CPack.html#cpack">CPack</a> (bundled with CMake) to create a nice installer
for your preferred platform. For example to build a <code>.deb</code> package, you should
run:</p>
<pre><code class="language-Shell">$ cpack -G DEB
</code></pre>
<h2><a class="header" href="#python-bindings" id="python-bindings">Python bindings</a></h2>
<p>Python bindings can be installed from the source package using <a href="https://github.com/takluyver/flit">Flit</a> Python
module by simply running:</p>
<pre><code class="language-Shell">$ flit install
</code></pre>
<p>or from <a href="https://pypi.python.org/pypi">PyPI</a> software repository using following command:</p>
<pre><code class="language-Shell">$ pip install neonrvm
</code></pre>
<h1><a class="header" href="#using-neonrvm" id="using-neonrvm">Using neonrvm</a></h1>
<p>Congratulations, you survived the build process! Following are general tips and
steps in order to train your model and perform predictions using neonrvm.</p>
<p>At this point it's a good idea to grab the original RVM paper and other related
papers to get a feeling of inner workings of the RVM technique and different
parameters. Please have a look at <code>example.c</code> and <code>example.py</code> for working
sample codes.</p>
<p>In order to keep repetitions in this document lower, Python bindings are briefly
documented. Errors reported by the library, will be raised as exceptions in
Python.</p>
<p><a href="http://www.miketipping.com/sparsebayes.htm">Sparse Bayesian Models (and the RVM)</a></p>
<h1><a class="header" href="#data-preparation" id="data-preparation">Data preparation</a></h1>
<p>This is the most important step in machine learning, and performance of your
model totally depends on it. Some general tips includes:</p>
<ul>
<li>Cleaning your data set from suspicious and wrong data</li>
<li>Feature engineering and giving more hints to the model</li>
<li>Normalizing and scaling input data</li>
<li>Randomizing input data order</li>
</ul>
<p>There is definitely more to that list, and it's strongly recommended to spend
more time on studying and preparation of input data than selection and tweaking
of the machine learning method. <a href="https://pandas.pydata.org/">pandas</a> and <a href="http://scikit-learn.org">scikit-learn</a> are your best
friends for data preparation if you are familiar with <a href="https://www.python.org/">Python</a> programming
language.</p>
<h1><a class="header" href="#design-matrix-preparation" id="design-matrix-preparation">Design matrix preparation</a></h1>
<p>Design matrix is a 2D matrix with <code>m</code> rows and <code>m</code> columns, with <code>m</code> being
equivalent to the number of input data samples. There is usually a column
consisting of <code>1.0</code> appended to that matrix to account for <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">bias</a>, which makes
it <code>m*(m+1)</code> or <code>m*n</code>, with <code>n</code> representing the number of <a href="https://en.wikipedia.org/wiki/Basis_function">basis functions</a>.</p>
<p>In plain English, basis functions show us how much close and similar input data
are to each other. And a <a href="https://en.wikipedia.org/wiki/Kernel_method">kernel function</a> decides how much similar our input
data are. Selection of the kernel function depends on the problem at hand, and
you can even mix multiple kernel functions together.</p>
<p>An <a href="https://en.wikipedia.org/wiki/Radial_basis_function">RBF</a> kernel with suitable parameter usually gives satisfactory results. Our
old buddy scikit-learn is there again to help you with a wide selection of
kernel functions and optimizing their parameters.</p>
<p>Before passing your design matrix to the neonrvm, make sure that it's stored in
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column major</a> order in memory. neonrvm will automatically append an extra
column for bias to the design matrix during <em>training</em> process, so you just need
to prepare a 2D <code>m*m</code> matrix.</p>
<h1><a class="header" href="#creating-training-cache" id="creating-training-cache">Creating training cache</a></h1>
<p><code>neonrvm_cache</code> structure acts as a cache for storing a couple of intermediate
training results and allows us to reuse memory as much as possible during
learning process.</p>
<h2><a class="header" href="#-cc" id="-cc">🚀 C/C++</a></h2>
<p>You can create one using <code>neonrvm_create_cache</code> function described below:</p>
<pre><code class="language-C">int neonrvm_create_cache(neonrvm_cache** cache, double* y, size_t count)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬆️ <code>[out] cache</code>: Pointer which it points to will be set to a freshly
allocated structure.</li>
<li>⬇️ <code>[in] y</code>: Data set output/target array, a copy will be made of its
contents.</li>
<li>⬇️ <code>[in] count</code>: <code>y</code> array elements count.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
</ul>
<p>Once you are done with <code>neonrvm_cache</code> structure and finished training process,
you should call <code>neonrvm_destroy_cache</code> to free up allocated memory.</p>
<pre><code class="language-C">int neonrvm_destroy_cache(neonrvm_cache* cache)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] cache</code>: Memory allocated for this structure will be released.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
</ul>
<h2><a class="header" href="#-python" id="-python">🐍 Python</a></h2>
<p>You simply need to create a new <code>Cache</code> instance, no need for manual memory
management.</p>
<pre><code class="language-Python">class Cache(y: numpy.ndarray)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] y</code>: Data set output/target array, a copy will be made of its
contents.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li>A new <code>Cache</code> instance.</li>
</ul>
<h1><a class="header" href="#creating-training-parameters" id="creating-training-parameters">Creating training parameters</a></h1>
<p><code>neonrvm_param</code> structure deals with training convergence conditions and initial
values.</p>
<h2><a class="header" href="#-cc-1" id="-cc-1">🚀 C/C++</a></h2>
<p>Use <code>neonrvm_create_param</code> function to create one:</p>
<pre><code class="language-C">int neonrvm_create_param(neonrvm_param** param,
                         double alpha_init, double alpha_max, double alpha_tol,
                         double beta_init, double basis_percent_min, size_t iter_max)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬆️ <code>[out] param</code>: Pointer which it points to will be set to a freshly
allocated structure.</li>
<li>⬇️ <code>[in] alpha_init</code>: Initial value for <em>alpha</em>. Must be a positive and small
number.</li>
<li>⬇️ <code>[in] alpha_max</code>: Basis functions associated with <em>alpha</em> value beyond this
limit will be purged. Must be a positive and big number.</li>
<li>⬇️ <code>[in] alpha_tol</code>: Training session will end if changes in <em>alpha</em> values
gets lower than this value. Must be a positive and small number.</li>
<li>⬇️ <code>[in] beta_init</code>: Initial value for <em>beta</em>. Must be a positive and small
value.</li>
<li>⬇️ <code>[in] basis_percent_min</code>: Training session will end if percentage of useful
basis functions during current training session gets lower than this value.
Must be a value in <code>[0.0, 100.0]</code> range.</li>
<li>⬇️ <code>[in] iter_max</code>: Training session will end if training loop iteration count
goes beyond this value. Must be a positive and non-zero number.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
</ul>
<p>Once you are done with <code>neonrvm_param</code> structure and finished training process,
you should call <code>neonrvm_destroy_param</code> to free up allocated memory.</p>
<pre><code class="language-C">int neonrvm_destroy_param(neonrvm_param* param)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] param</code>: Memory allocated for this structure will be released.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
</ul>
<h2><a class="header" href="#-python-1" id="-python-1">🐍 Python</a></h2>
<p>A new <code>Param</code> instance should be created:</p>
<pre><code class="language-Python">class Param(alpha_init: float, alpha_max: float, alpha_tol: float,
            beta_init: float, basis_percent_min: float, iter_max: int)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] alpha_init</code>: Initial value for <em>alpha</em>. Must be a positive and small
number.</li>
<li>⬇️ <code>[in] alpha_max</code>: Basis functions associated with <em>alpha</em> value beyond this
limit will be purged. Must be a positive and big number.</li>
<li>⬇️ <code>[in] alpha_tol</code>: Training session will end if changes in <em>alpha</em> values
gets lower than this value. Must be a positive and small number.</li>
<li>⬇️ <code>[in] beta_init</code>: Initial value for <em>beta</em>. Must be a positive and small
value.</li>
<li>⬇️ <code>[in] basis_percent_min</code>: Training session will end if percentage of useful
basis functions during current training session gets lower than this value.
Must be a value in <code>[0.0, 100.0]</code> range.</li>
<li>⬇️ <code>[in] iter_max</code>: Training session will end if training loop iteration count
goes beyond this value. Must be a positive and non-zero number.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li>A new <code>Param</code> instance.</li>
</ul>
<h1><a class="header" href="#training-the-model" id="training-the-model">Training the model</a></h1>
<p><code>neonrvm_train</code> function requires a pair of training parameter structures, one
for just getting rid of pretty useless basis functions, and another one for
polishing the training results. In the first one you usually want to keep
majority of basis functions, while in the last one you want to reduce number of
basis functions as much as possible in order to achieve a more general and
sparse model.</p>
<p>By choosing a <em>batch size</em> value smaller than total input basis function count,
the model will be trained incrementally using the first training parameter
structure, and will get polished using the last training parameter structure in
the end.</p>
<p>neonrvm has been carefully designed to handle multiple training scenarios.
Different scenarios are discussed below:</p>
<h2><a class="header" href="#a-optimizing-kernel-parameters" id="a-optimizing-kernel-parameters">A) Optimizing kernel parameters</a></h2>
<p>During this period one needs to rapidly try different kernel parameters either
using an optimization algorithm (<a href="https://github.com/hyperopt/hyperopt">Hyperopt</a> to the rescue) or brute force method
to achieve optimal kernel parameters. Make sure that the optimization algorithm
can deal with possible training failures.</p>
<p>In this case users need to use small batch sizes, and training parameters with
more relaxed convergence conditions. In other words, a highly polished and
sparse model isn't required.</p>
<h2><a class="header" href="#b-finalized-kernel-parameters-and-model" id="b-finalized-kernel-parameters-and-model">B) Finalized kernel parameters and model</a></h2>
<p>When you are finished with tuning kernel parameters and trying different model
creation ideas, you need access to the best basis functions and finely tuned
weights associated to them in order to make accurate predictions.</p>
<p>You need to throw bigger training batch sizes at neonrvm, and use training
parameters with low basis function percentage and high iteration count for the
polishing step in this case.</p>
<h2><a class="header" href="#-big-data-sets" id="-big-data-sets">🍔) Big data sets</a></h2>
<p>Memory and storage requirements do quickly skyrocket when dealing with large
data sets. You don't necessarily need to feed the whole design matrix to the
neonrvm all at once. It can also be fed in smaller chunks by loading different
design matrix parts from disk, or simply generating them on the fly.</p>
<p>neonrvm allows users to split the design matrix and perform the training process
incrementally at higher level through caching mechanism provided. You just need
to make multiple <code>neonrvm_train</code> function calls and neonrvm will store the
useful basis functions in the given <code>neonrvm_cache</code> on the go.</p>
<p>It is a good idea to group together similar data using <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a> algorithms,
and feed neonrvm with a mixture of them incrementally.</p>
<h2><a class="header" href="#-cc-2" id="-cc-2">🚀 C/C++</a></h2>
<p>Alright, now that we covered the different use cases, it's time to get familiar
with the <code>neonrvm_train</code> function:</p>
<pre><code class="language-C">int neonrvm_train(neonrvm_cache* cache, neonrvm_param* param1, neonrvm_param* param2,
                  double* phi, size_t* index, size_t count, size_t batch_size_max)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] cache</code>: Stores intermediate variables and training results.</li>
<li>⬇️ <code>[in] param1</code>: Incremental training parameters.</li>
<li>⬇️ <code>[in] param2</code>: Final polish parameters.</li>
<li>⬇️ <code>[in] phi</code>: Column major design matrix, with row count equivalent to the
total sample count, and column count equivalent to the given basis function
<em>count</em>. A copy of useful basis functions will be kept inside the training
<em>cache</em>.</li>
<li>⬇️ <code>[in] index</code>: Basis function indices, a vector with elements count
equivalent to the given basis function <em>count</em>. A copy of useful basis
function indices will be kept inside the training <em>cache</em>. Must be a vector
of positive numbers, and shouldn't contain any value equal to the
<code>SIZE_MAX</code>, which is used internally to identify bias index.</li>
<li>⬇️ <code>[in] count</code>: Number of basis functions given. Must be a positive non-zero
number.</li>
<li>⬇️ <code>[in] batch_size_max</code>: Maximum number of basis functions in every
incremental training session. Must be a positive non-zero value.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
<li><code>NEONRVM_LAPACK_ERROR</code>: When LAPACK fails to perform factorization or solve
equations.</li>
<li><code>NEONRVM_MATH_ERROR</code>: When <code>NaN</code> or <code>∞</code> numbers show up in the calculations.</li>
</ul>
<h2><a class="header" href="#-python-2" id="-python-2">🐍 Python</a></h2>
<pre><code class="language-Python">def train(cache: Cache, param1: Param, param2: Param,
          phi: numpy.ndarray, index: numpy.ndarray, batch_size_max: int)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] cache</code>: Stores intermediate variables and training results.</li>
<li>⬇️ <code>[in] param1</code>: Incremental training parameters.</li>
<li>⬇️ <code>[in] param2</code>: Final polish parameters.</li>
<li>⬇️ <code>[in] phi</code>: Column major design matrix, with row count equivalent to the
total sample count, and column count equivalent to the given basis function
<em>count</em>. A copy of useful basis functions will be kept inside the training
<em>cache</em>.</li>
<li>⬇️ <code>[in] index</code>: Basis function indices, a vector with elements count
equivalent to the given basis function <em>count</em>. A copy of useful basis
function indices will be kept inside the training <em>cache</em>. Must be a vector
of positive numbers, and shouldn't contain any value equal to the
<code>SIZE_MAX</code>, which is used internally to identify bias index.</li>
<li>⬇️ <code>[in] batch_size_max</code>: Maximum number of basis functions in every
incremental training session. Must be a positive non-zero value.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li>Nothing that I'm aware of.</li>
</ul>
<h1><a class="header" href="#getting-the-training-results" id="getting-the-training-results">Getting the training results</a></h1>
<p>After successful completion of training process, training results including
useful basis function indices and their associated weights can be queried using
<code>neonrvm_get_training_stats</code> and <code>neonrvm_get_training_results</code> functions.</p>
<p>You should first get the useful basis functions count, and then allocate enough
memory for the basis function indices and weights vectors so neonrvm can fill
them for you.</p>
<h2><a class="header" href="#-cc-3" id="-cc-3">🚀 C/C++</a></h2>
<pre><code class="language-C">int neonrvm_get_training_stats(neonrvm_cache* cache, size_t* basis_count, bool* bias_used)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] cache</code>: Contains intermediate variables and training results.</li>
<li>⬆️ <code>[out] basis_count</code>: Value pointed to will be set to the number of useful
basis functions. (Includes <em>bias</em> too if it was found useful)</li>
<li>⬆️ <code>[out] bias_used</code>: Value pointed to will be set to <code>true</code> if <em>bias</em> was
useful during training.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
</ul>
<pre><code class="language-C">int neonrvm_get_training_results(neonrvm_cache* cache, size_t* index, double* mu)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] cache</code>: Contains intermediate variables and training results.</li>
<li>⬆️ <code>[out] index</code>: Vector with enough room for useful basis function indices.
Last element contains <code>SIZE_MAX</code> if <em>bias</em> was found to be useful.</li>
<li>⬆️ <code>[out] mu</code>: Vector with enough room for useful basis function weights. Last
element contains <em>bias</em> weight, if <em>bias</em> was found to be useful.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
</ul>
<h2><a class="header" href="#-python-3" id="-python-3">🐍 Python</a></h2>
<p>A single function call is enough:</p>
<pre><code class="language-Python">def get_training_results(cache: Cache)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] cache</code>: Contains intermediate variables and training results.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>index: numpy.ndarray</code>: Vector of useful basis function indices. Last element
contains <code>SIZE_MAX</code> if <em>bias</em> was found to be useful.</li>
<li><code>mu: numpy.ndarray</code>: Vector of useful basis function weights. Last element
contains <em>bias</em> weight, if <em>bias</em> was found to be useful.</li>
<li><code>basis_count: int</code>: Number of useful basis functions. (Includes <em>bias</em> too if
it was found useful)</li>
<li><code>bias_used: bool</code>: Whether <em>bias</em> was useful during training.</li>
</ul>
<h1><a class="header" href="#making-predictions" id="making-predictions">Making predictions</a></h1>
<p>Now that you have the indices and weights of the useful data in hand, you can
make predictions. In order to make prediction with new input data and unknown
outcomes, you should create a new design matrix like what was discussed in <em>Step
1</em>, but this time getting populated with closeness and similarities between new
input data, and useful data which we found their indices previously.</p>
<p>If <em>bias</em> was found useful during training process, you need to manually append
a column of <code>1.0</code> to your new matrix. The new matrix should have row count equal
to the number of new input data samples, and column count equal to the number of
useful basis functions.</p>
<p>Predictions are simply made by multiplying the result matrix and weights vector.
Output vector contains the prediction outcomes, with a length equal to the
number of new input data samples.</p>
<h2><a class="header" href="#-cc-4" id="-cc-4">🚀 C/C++</a></h2>
<p>You can use the <code>neonrvm_predict</code> function to make predictions.</p>
<pre><code class="language-C">int neonrvm_predict(double* phi, double* mu,
                    size_t sample_count, size_t basis_count, double* y)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] phi</code>: Column major matrix, with row count equivalent to the
<em>sample_count</em>, and column count equivalent to the <em>basis_count</em>.</li>
<li>⬇️ <code>[in] mu</code>: Vector of associated basis function weights, with number of
elements equal to the <em>basis_count</em>.</li>
<li>⬇️ <code>[in] sample_count</code>: Number of input data samples with unknown outcomes.</li>
<li>⬇️ <code>[in] basis_count</code>: Number of useful basis functions.</li>
<li>⬆️ <code>[out] y</code>: Vector of predictions made for input data with unknown outcomes,
with enough room and number of elements equal to the <em>sample_count</em>.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>NEONRVM_SUCCESS</code>: After successful execution.</li>
<li><code>NEONRVM_INVALID_Px</code>: When facing erroneous parameters.</li>
<li><code>NEONRVM_MATH_ERROR</code>: When <code>NaN</code> or <code>∞</code> numbers show up in the calculations.</li>
</ul>
<h2><a class="header" href="#-python-4" id="-python-4">🐍 Python</a></h2>
<p>Number of <code>phi</code> columns and <code>mu</code> length should match.</p>
<pre><code class="language-Python">def predict(phi: np.ndarray, mu: np.ndarray)
</code></pre>
<p>➡️ <em>Parameters</em></p>
<ul>
<li>⬇️ <code>[in] phi</code>: Column major matrix, with row count equivalent to the
<em>sample_count</em>, and column count equivalent to the <em>basis_count</em>.</li>
<li>⬇️ <code>[in] mu</code>: Vector of associated basis function weights, with number of
elements equal to the <em>basis_count</em>.</li>
</ul>
<p>⬅️ <em>Returns</em></p>
<ul>
<li><code>y: numpy.ndarray</code>: Vector of predictions made for input data with unknown
outcomes, with number of elements equal to the <em>sample_count</em>.</li>
</ul>
<h1><a class="header" href="#license" id="license">License</a></h1>
<ul>
<li>
<p>neonrvm is licensed under the <a href="https://en.wikipedia.org/wiki/MIT_License">MIT</a> license. Please see <code>LICENSE</code> for more
details.</p>
</li>
<li>
<p>neonrvm includes code from <a href="http://www.netlib.org/lapack/">Netlib LAPACK</a> library, which is licensed under a
<a href="http://www.netlib.org/lapack/LICENSE.txt">modified BSD license</a>.</p>
</li>
<li>
<p>The relevance vector machine is <a href="https://patents.google.com/patent/US6633857">patented</a> in the United States by
<a href="https://www.microsoft.com">Microsoft</a>.</p>
</li>
</ul>
<h1><a class="header" href="#future-work" id="future-work">Future work</a></h1>
<ul>
<li>Investigate methods to make learning process numerically more stable</li>
<li>Implement classification</li>
<li>Create higher level wrappers and programming language bindings</li>
<li>Improve documentation</li>
</ul>
<h1><a class="header" href="#reference" id="reference">Reference</a></h1>
<ul>
<li>Tipping, M. E. (2001). Sparse Bayesian learning and the relevance vector machine. Journal of machine learning research, 1(Jun), 211-244.</li>
<li>Ben-Shimon, D., &amp; Shmilovici, A. (2006). Accelerating the relevance vector machine via data partitioning. Foundations of Computing and Decision Sciences, 31(1), 27-42.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        
        <!-- Google Analytics Tag -->
        <script type="text/javascript">
            var localAddrs = ["localhost", "127.0.0.1", ""];

            // make sure we don't activate google analytics if the developer is
            // inspecting the book locally...
            if (localAddrs.indexOf(document.location.hostname) === -1) {
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-172493032-1', 'auto');
                ga('send', 'pageview');
            }
        </script>
        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
